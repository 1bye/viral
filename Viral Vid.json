{"id":"9bd1b343-664a-47bb-ba3e-4d9653a827a7","data":{"nodes":[{"id":"CustomComponent-SlW53","type":"genericNode","position":{"x":311.05223656789275,"y":277.41150134516175},"data":{"type":"OpenAIWhisper","node":{"template":{"_type":"Component","audio":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"audio","display_name":"Audio File","advanced":false,"input_types":["bytes"],"dynamic":false,"info":"","title_case":false,"type":"other"},"apiKey":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"07622d868efa446aaec96e2bb2b6866e","name":"apiKey","display_name":"OpenAI API Key","advanced":false,"input_types":["bytes"],"dynamic":false,"info":"","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output, HandleInput\r\nfrom langflow.schema import Data\r\nimport json\r\nimport requests\r\n\r\nclass OpenAIWhisperComponent(Component):\r\n    display_name = \"OpenAI Whisper\"\r\n    icon = \"custom_components\"\r\n    name = \"OpenAIWhisper\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"apiKey\", display_name=\"OpenAI API Key\", input_types=[\"bytes\"]),\r\n        HandleInput(name=\"audio\", display_name=\"Audio File\", input_types=[\"bytes\"])\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Data:\r\n        url = 'https://api.aimlapi.com/stt'\r\n\r\n        headers = {\r\n            'Authorization': f'Bearer {self.apiKey}'\r\n        }\r\n\r\n        files = {\r\n            'audio': ('audio.mp3', self.audio, 'audio/mp3'),\r\n            'model': (None, '#g1_nova-2-general')\r\n        }\r\n        \r\n        response = requests.post(url, headers=headers, files=files)\r\n        \r\n        response_data = response.json()\r\n        data = Data(data=response_data)  # Use keyword arguments to initialize Data\r\n        self.status = data\r\n        return data\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"icon":"custom_components","base_classes":["Data"],"display_name":"OpenAI Whisper","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["apiKey","audio"],"beta":false,"edited":true},"id":"CustomComponent-SlW53","display_name":"OpenAI Whisper"},"selected":false,"width":384,"height":348,"positionAbsolute":{"x":311.05223656789275,"y":277.41150134516175},"dragging":false},{"id":"CustomComponent-4OU19","type":"genericNode","position":{"x":-248.87276657168434,"y":311.60091889864833},"data":{"type":"AudioFile Loader","node":{"template":{"_type":"Component","path":{"trace_as_metadata":true,"file_path":"9bd1b343-664a-47bb-ba3e-4d9653a827a7\\audio.mp3","fileTypes":["mp3"],"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: mp3","title_case":false,"type":"file","load_from_db":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\r\n\r\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\r\nfrom langflow.custom import Component\r\nfrom langflow.io import BoolInput, FileInput, Output\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass AudioFileComponent(Component):\r\n    display_name = \"AudioFiel\"\r\n    description = \"AudioFile loader\"\r\n    icon = \"audio\"\r\n    name = \"AudioFile Loader\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"path\",\r\n            display_name=\"Path\",\r\n            file_types=[\"mp3\"],\r\n            info=f\"Supported file types: mp3\",\r\n        ),\r\n        BoolInput(\r\n            name=\"silent_errors\",\r\n            display_name=\"Silent Errors\",\r\n            advanced=True,\r\n            info=\"If true, errors will not raise an exception.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Audio File\", name=\"audioFile\", method=\"load_file\"),\r\n    ]\r\n\r\n    def load_file(self) -> bytes:\r\n        if not self.path:\r\n            raise ValueError(\"Please, upload a file to use this component.\")\r\n        resolved_path = self.resolve_path(self.path)\r\n        silent_errors = self.silent_errors\r\n\r\n        extension = Path(resolved_path).suffix[1:].lower()\r\n\r\n        if extension not in [\"mp3\"]:\r\n            raise ValueError(f\"Unsupported audio file type: {extension}\")\r\n\r\n        try:\r\n            with open(resolved_path, 'rb') as file:\r\n                data = file.read()\r\n            self.status = data\r\n            return data\r\n        except FileNotFoundError:\r\n            raise ValueError(f\"File not found at {resolved_path}\")\r\n        except Exception as e:\r\n            if not silent_errors:\r\n                raise e\r\n            else:\r\n                raise ValueError(f\"Error: {str(e)}\")\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","title_case":false,"type":"bool"}},"description":"AudioFile loader","icon":"audio","base_classes":["bytes"],"display_name":"Audio File","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["bytes"],"selected":"bytes","name":"audioFile","display_name":"Audio File","method":"load_file","value":"__UNDEFINED__","cache":true}],"field_order":["path","silent_errors"],"beta":false,"edited":true},"id":"CustomComponent-4OU19","description":"AudioFile loader","display_name":"Audio File"},"selected":false,"width":384,"height":300,"positionAbsolute":{"x":-248.87276657168434,"y":311.60091889864833},"dragging":false},{"id":"ChatOutput-DZ1VS","type":"genericNode","position":{"x":1291.4912668963884,"y":484.72191548695406},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.memory import store_message\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"},"store_message":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"store_message","display_name":"Store Messages","advanced":true,"dynamic":false,"info":"Store the message in the history.","title_case":false,"type":"bool"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","store_message","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-DZ1VS"},"selected":false,"width":384,"height":308,"positionAbsolute":{"x":1291.4912668963884,"y":484.72191548695406},"dragging":false},{"id":"ParseData-aODsi","type":"genericNode","position":{"x":863.8435210000873,"y":506.8206095470473},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{results}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-aODsi"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":863.8435210000873,"y":506.8206095470473},"dragging":false},{"id":"CustomComponent-5TG3q","type":"genericNode","position":{"x":785.1492116919073,"y":934.8957729010494},"data":{"type":"TranscriptAudio","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\n\r\nclass ToTranscriptComponent(Component):\r\n    display_name = \"Audio Transcript to Text Transcript\"\r\n    description = \"Transforms Audio Transcript into Text Transcript\"\r\n    documentation: str = \"http://docs.langflow.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"TranscriptAudio\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> str:\r\n        transcript_json = self.data.results \r\n\r\n        sentences = []\r\n        for paragraph in transcript_json[\"channels\"][0][\"alternatives\"][0][\"paragraphs\"][\"paragraphs\"]:\r\n            for sentence in paragraph[\"sentences\"]:\r\n                start_time = sentence[\"start\"]\r\n                end_time = sentence[\"end\"]\r\n                text = sentence[\"text\"]\r\n                sentences.append(f\"[{start_time:.2f}s -> {end_time:.2f}s] {text}\")\r\n\r\n        # Join all sentences into a single output\r\n        output = \"\\n\".join(sentences)\r\n        self.status = output\r\n        return output\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Transforms Audio Transcript into Text Transcript","icon":"custom_components","base_classes":["Text"],"display_name":"Audio Transcript to Text Transcript","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Text"],"selected":"Text","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["data"],"beta":false,"edited":true},"id":"CustomComponent-5TG3q","description":"Transforms Audio Transcript into Text Transcript","display_name":"Audio Transcript to Text Transcript"},"selected":false,"width":384,"height":262,"dragging":false,"positionAbsolute":{"x":785.1492116919073,"y":934.8957729010494}},{"id":"OpenAIModel-kxaTe","type":"genericNode","position":{"x":1860.873307487175,"y":973.6846284183698},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-4o","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"https://api.aimlapi.com/","name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"id":"OpenAIModel-kxaTe"},"selected":false,"width":384,"height":621,"dragging":false,"positionAbsolute":{"x":1860.873307487175,"y":973.6846284183698}},{"id":"Prompt-4NImD","type":"genericNode","position":{"x":1313.770597381544,"y":1059.7435909717392},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"You are an AI language model tasked with dividing the transcription of a video into a specified number of coherent and meaningful chunks. These chunks should be suitable for posting on social media platforms. Here are the guidelines for this task:\n\n1) **Coherence**: Each chunk should represent a complete and coherent idea or segment from the video. Avoid splitting sentences or breaking up thoughts mid-way.\n2) **Length**: Aim for chunks that are between \\`{min_seconds}\\` and \\`{max_seconds}\\` in spoken length. This translates to around \\`{min_words}\\`-\\`{max_words}\\` words per chunk, depending on the speaking speed.\n3) **Context**: Ensure that each chunk provides enough context for the viewer to understand the content without needing to see the previous or next chunk.\n4) **Engagement**: Select natural breaking points that maintain the interest of the audience and encourage them to watch the next chunk. Look for transitions in topics, changes in speakers, or natural pauses in the conversation.\n5) **Clarity**: If a section contains complex or dense information, consider slightly shorter chunks to ensure clarity and retention of information.\n6) **Formatting**: Provide the chunks as a list with clear separations, using labels like \"Chunk 1,\" \"Chunk 2,\" etc.\n\n**Transcription Structure:**\n\nThe transcription is structured with timestamps indicating the start and end times of each segment. Each segment looks like this:\n\n\\`\\`\\`transcription\n[0.00s -> 2.34s] Bla... Bla... Bla...\n\\`\\`\\`\n\nWhere \"s\" denotes seconds. Use these timestamps to help identify natural breaking points and ensure each chunk falls within the desired length range.\n\nHere is a transcription of a video:\n\n\\`\\`\\`transcription\n{transcript}\n\\`\\`\\`\n\n**Important**: The transcription must remain unchanged. Use the exact text and timestamps provided. The transcription should be divided into exactly \\`{num_chunks}\\` chunks, with each chunk between \\`{min_seconds}\\` and \\`{max_seconds}\\` seconds in length.\n\nReturn each chunk using the following structure:\n\n\\`\\`\\`\n**Chunk 1:**\n[0.00s -> 2.34s]\n- [0.00s -> 0.94s] Bla... Bla... Bla...\n- [0.94s -> 1.84s] Bla... Bla... Bla... \n- [1.84s -> 2.34s] Bla... Bla... Bla... \n\\`\\`\\`\n\nPlease divide this transcription into \\`{num_chunks}\\` coherent and meaningful chunks suitable for social media posting. Ensure that each chunk respects the minimum and maximum length constraints and contains complete ideas without breaking sentences or thoughts mid-way. \nReturn ONLY the chunks formatted as shown above, dont return any another data, ONLY chunks\n\n----------------------------------\n\nFor example:\nIf the transcription is:\n\n\\`\\`\\`transcription\n[0.00s -> 10.00s] In this video, we are building and giving away 100 houses, and each home is going to change a family's life.\n[10.00s -> 20.00s] Like this family, who didn't have a house to call their own, and they have no idea we just built them one.\n[20.00s -> 30.00s] Take off your blindfolds and turn around. Behind you is your brand new home.\n[30.00s -> 40.00s] Oh, I was not expecting that reaction. She is freaking out.\n[40.00s -> 50.00s] I always want them to have a bunk with me. Come too.\n[50.00s -> 60.00s] And this is just the first of a hundred houses we're giving away. First. I'm glad they're happy. Let's go give away another house.\n[60.00s -> 110.00s] With every single home we're building in this video, we're improving quality of life for families who don't have a safe space to call home.\n\\`\\`\\`\n\nThe resulting chunks should look like:\n\n\\`\\`\\`\n**Chunk 1:**\n[0.00s -> 40.00s]\n- [0.00s -> 10.00s] In this video, we are building and giving away 100 houses, and each home is going to change a family's life.\n- [10.00s -> 20.00s] Like this family, who didn't have a house to call their own, and they have no idea we just built them one.\n- [20.00s -> 30.00s] Take off your blindfolds and turn around. Behind you is your brand new home.\n- [30.00s -> 40.00s] Oh, I was not expecting that reaction. She is freaking out.\n\n**Chunk 2:**\n[40.00s -> 70.00s]\n- [40.00s -> 50.00s] I always want them to have a bunk with me. Come too.\n- [50.00s -> 60.00s] And this is just the first of a hundred houses we're giving away. First. I'm glad they're happy. Let's go give away another house.\n- [60.00s -> 110.00s] With every single home we're building in this video, we're improving quality of life for families who don't have a safe space to call home.\n\\`\\`\\`\n","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"min_seconds":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"5","fileTypes":[],"file_path":"","password":false,"name":"min_seconds","display_name":"min_seconds","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"max_seconds":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"30","fileTypes":[],"file_path":"","password":false,"name":"max_seconds","display_name":"max_seconds","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"min_words":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"10","fileTypes":[],"file_path":"","password":false,"name":"min_words","display_name":"min_words","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"max_words":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"300","fileTypes":[],"file_path":"","password":false,"name":"max_words","display_name":"max_words","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"transcript":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcript","display_name":"transcript","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"num_chunks":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"2","fileTypes":[],"file_path":"","password":false,"name":"num_chunks","display_name":"num_chunks","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["min_seconds","max_seconds","min_words","max_words","transcript","num_chunks"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-4NImD","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":890,"positionAbsolute":{"x":1313.770597381544,"y":1059.7435909717392},"dragging":false},{"id":"CustomComponent-wO22z","type":"genericNode","position":{"x":2452.0822735910074,"y":926.787379148137},"data":{"type":"TranscriptionChunk","node":{"template":{"_type":"Component","chunks":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chunks","display_name":"Chunks","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import re\r\nimport json\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass TranscriptionChunkComponent(Component):\r\n    display_name = \"Transcription Chunk\"\r\n    description = \"Transforms LLM Output to Transcription Chunk\"\r\n    documentation = \"http://docs.langflow.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"TranscriptionChunk\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"chunks\", display_name=\"Chunks\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Data:\r\n        chunks = self.chunks.split(\"\\n\\n\")\r\n\r\n        result = {\r\n            \"chunks\": []\r\n        }\r\n        \r\n        for chunk in chunks:\r\n            lines = chunk.split(\"\\n\")\r\n            chunk_header = lines[0]\r\n            content_arr = lines[1:]\r\n\r\n            # Extracting start and end times from chunk header\r\n            matches = re.findall(r\"\\[(\\d+(\\.\\d*)?)s\\s*->\\s*(\\d+(\\.\\d*)?)s\\]\", chunk_header)\r\n\r\n            if matches:\r\n                start_time = float(matches[0][0])\r\n                end_time = float(matches[0][2])\r\n            else:\r\n                # If chunk header doesn't provide times, derive from segments\r\n                segments = []\r\n                segment_regex = re.compile(r\"-\\s*\\[(\\d+(\\.\\d*)?)s\\s*->\\s*(\\d+(\\.\\d*)?)s\\]\\s*(.*)\")\r\n                for line in content_arr:\r\n                    match = segment_regex.match(line)\r\n                    if match:\r\n                        segment_text = match.group(5).strip() if match.group(5) else \"\"\r\n                        segments.append({\r\n                            \"start\": float(match.group(1)),\r\n                            \"end\": float(match.group(3)),\r\n                            \"text\": segment_text\r\n                        })\r\n\r\n                # Use start time of first segment and end time of last segment\r\n                if segments:\r\n                    start_time = segments[0]['start']\r\n                    end_time = segments[-1]['end']\r\n                else:\r\n                    start_time = 0\r\n                    end_time = 0\r\n\r\n            # Build chunk dictionary\r\n            chunk_dict = {\r\n                \"text\": ' '.join([line.split(\"] \")[-1].strip() for line in content_arr]),\r\n                \"start\": start_time,\r\n                \"end\": end_time,\r\n                \"segments\": segments  # Include segments in the output\r\n            }\r\n            result[\"chunks\"].append(chunk_dict)\r\n\r\n        data = Data(data=result)\r\n        self.status = data\r\n        return data\r\n\r\n# Example usage:\r\n# Assuming `self.chunks` is provided by the framework with the input chunks.\r\n# Instantiate and use within your Langflow environment as per your setup.\r\n\r\n# Note: Ensure to adapt the `chunk_header` and `content_arr` indices as per your specific input structure.\r\n\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Transforms LLM Output to Transcription Chunk","icon":"custom_components","base_classes":["Data"],"display_name":"Transcription Chunk","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["chunks"],"beta":false,"edited":false},"id":"CustomComponent-wO22z","description":"Transforms LLM Output to Transcription Chunk","display_name":"Transcription Chunk"},"selected":false,"width":384,"height":306,"dragging":false,"positionAbsolute":{"x":2452.0822735910074,"y":926.787379148137}},{"id":"CustomComponent-OLZ9A","type":"genericNode","position":{"x":3032.9667953079293,"y":1293.4691612059148},"data":{"type":"SliceVideo","node":{"template":{"_type":"Component","chunks":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chunks","display_name":"Chunks","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"video":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"video","display_name":"Video File","advanced":false,"input_types":["bytes"],"dynamic":false,"info":"","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import os\r\nimport subprocess\r\nimport tempfile\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, HandleInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass SliceVideoComponent(Component):\r\n    display_name = \"Slice Video\"\r\n    description = \"Slices Video based on provided chunks using ffmpeg CLI and saves into default user videos directory\"\r\n    documentation = \"http://docs.langflow.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"SliceVideo\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"chunks\", display_name=\"Chunks\"),\r\n        HandleInput(name=\"video\", display_name=\"Video File\", input_types=[\"bytes\"])\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    async def build_output(self) -> Data:\r\n        try:\r\n            chunks_data = self.chunks\r\n            video_bytes = self.video\r\n\r\n            # Access the 'chunks' attribute from Data object\r\n            chunks = chunks_data.data.get('chunks', [])\r\n\r\n            # Create a temporary file to save video bytes\r\n            with tempfile.NamedTemporaryFile(delete=False) as tmp_video:\r\n                tmp_video.write(video_bytes)\r\n                tmp_video.flush()\r\n                tmp_video_path = tmp_video.name\r\n\r\n            # Get default user videos directory on Windows\r\n            user_videos_dir = os.path.expanduser('~/Videos')\r\n            os.makedirs(user_videos_dir, exist_ok=True)\r\n\r\n            # List to store paths of sliced video files\r\n            sliced_video_paths = []\r\n\r\n            # Process each chunk\r\n            for idx, chunk in enumerate(chunks, start=1):\r\n                start_time = chunk.get('start', 0)\r\n                end_time = chunk.get('end', 0)\r\n\r\n                # Define output file path in user videos directory\r\n                output_file = os.path.join(user_videos_dir, f'sliced_video_{idx}.mp4')\r\n\r\n                # Prepare ffmpeg command\r\n                ffmpeg_command = [\r\n                    'ffmpeg',\r\n                    '-y',  # Overwrite output files without asking\r\n                    '-i', tmp_video_path,  # Input file path\r\n                    '-ss', str(start_time),  # Start time\r\n                    '-to', str(end_time),  # End time\r\n                    '-c:v', 'copy',  # Copy video codec\r\n                    '-c:a', 'copy',  # Copy audio codec\r\n                    '-f', 'mp4',  # Output format\r\n                    output_file  # Output file path\r\n                ]\r\n\r\n                # Execute ffmpeg command\r\n                subprocess.run(ffmpeg_command, check=True)\r\n\r\n                # Append sliced video file path to the list\r\n                sliced_video_paths.append(output_file)\r\n\r\n            # Return as Data object containing array of video file paths\r\n            return Data(data={\"sliced_video_paths\": sliced_video_paths})\r\n\r\n        except Exception as e:\r\n            # Handle any exceptions, log the error\r\n            print(f\"Error in build_output: {e}\")\r\n            # You may want to raise the exception or return an error Data object here\r\n            raise e\r\n        finally:\r\n            # Clean up temporary video file\r\n            if tmp_video_path and os.path.exists(tmp_video_path):\r\n                os.remove(tmp_video_path)\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Slices Video based on provided chunks using ffmpeg CLI and saves into default user videos directory","icon":"custom_components","base_classes":["Data"],"display_name":"Slice Video","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["chunks","video"],"beta":false,"edited":true},"id":"CustomComponent-OLZ9A","description":"Slices Video based on provided chunks using ffmpeg CLI and saves into default user videos directory","display_name":"Slice Video"},"selected":false,"width":384,"height":366,"dragging":false,"positionAbsolute":{"x":3032.9667953079293,"y":1293.4691612059148}},{"id":"CustomComponent-KuTs4","type":"genericNode","position":{"x":2460.964683662957,"y":1456.7235068611622},"data":{"type":"VideoFile Loader","node":{"template":{"_type":"Component","path":{"trace_as_metadata":true,"file_path":"9bd1b343-664a-47bb-ba3e-4d9653a827a7\\f.mp4","fileTypes":["mp4"],"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"Supported file types: mp4","title_case":false,"type":"file"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from pathlib import Path\r\n\r\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\r\nfrom langflow.custom import Component\r\nfrom langflow.io import BoolInput, FileInput, Output\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass VideoFileComponent(Component):\r\n    display_name = \"VideoFile\"\r\n    description = \"VideoFile loader\"\r\n    icon = \"video\"\r\n    name = \"VideoFile Loader\"\r\n\r\n    inputs = [\r\n        FileInput(\r\n            name=\"path\",\r\n            display_name=\"Path\",\r\n            file_types=[\"mp4\"],\r\n            info=f\"Supported file types: mp4\",\r\n        ),\r\n        BoolInput(\r\n            name=\"silent_errors\",\r\n            display_name=\"Silent Errors\",\r\n            advanced=True,\r\n            info=\"If true, errors will not raise an exception.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Video File\", name=\"videoFile\", method=\"load_file\"),\r\n    ]\r\n\r\n    def load_file(self) -> bytes:\r\n        if not self.path:\r\n            raise ValueError(\"Please, upload a file to use this component.\")\r\n        resolved_path = self.resolve_path(self.path)\r\n        silent_errors = self.silent_errors\r\n\r\n        extension = Path(resolved_path).suffix[1:].lower()\r\n\r\n        if extension not in [\"mp4\"]:\r\n            raise ValueError(f\"Unsupported video file type: {extension}\")\r\n\r\n        try:\r\n            with open(resolved_path, 'rb') as file:\r\n                data = file.read()\r\n            return data\r\n        except FileNotFoundError:\r\n            raise ValueError(f\"File not found at {resolved_path}\")\r\n        except Exception as e:\r\n            if not silent_errors:\r\n                raise e\r\n            else:\r\n                raise ValueError(f\"Error: {str(e)}\")\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"silent_errors":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"silent_errors","display_name":"Silent Errors","advanced":true,"dynamic":false,"info":"If true, errors will not raise an exception.","title_case":false,"type":"bool"}},"description":"VideoFile loader","icon":"video","base_classes":["bytes"],"display_name":"Video File","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["bytes"],"selected":"bytes","name":"videoFile","display_name":"Video File","method":"load_file","value":"__UNDEFINED__","cache":true}],"field_order":["path","silent_errors"],"beta":false,"edited":true},"id":"CustomComponent-KuTs4","description":"VideoFile loader","display_name":"Custom Component"},"selected":false,"width":384,"height":300,"dragging":false,"positionAbsolute":{"x":2460.964683662957,"y":1456.7235068611622}},{"id":"CustomComponent-mWoHe","type":"genericNode","position":{"x":3689.9803712224893,"y":972.8060060727237},"data":{"type":"OverlayTranscription","node":{"template":{"_type":"Component","chunks":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"chunks","display_name":"Chunks","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"paths":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"paths","display_name":"Paths to Videos","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import os\r\nfrom pathlib import Path\r\nimport ffmpeg\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass OverlayTranscriptionComponent(Component):\r\n    display_name = \"Overlay Transcription\"\r\n    description = \"Overlay transcription subtitles on videos based on provided chunks using ffmpeg-python\"\r\n    documentation = \"http://docs.langflow.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"OverlayTranscription\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"chunks\", display_name=\"Chunks\"),\r\n        DataInput(name=\"paths\", display_name=\"Paths to Videos\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    async def build_output(self) -> Data:\r\n        try:\r\n            chunks_data = self.chunks\r\n            video_paths = self.paths.data.get('sliced_video_paths', [])\r\n\r\n            # Access the 'chunks' attribute from Data object\r\n            chunks = chunks_data.data.get('chunks', [])\r\n\r\n            # Get Windows user's Videos folder path\r\n            videos_folder = Path(os.getenv('USERPROFILE')) / 'Videos'\r\n            srt_folder = os.path.join(videos_folder, \"srt\")\r\n\r\n            # Ensure 'srt' folder exists, create if not\r\n            os.makedirs(srt_folder, exist_ok=True)\r\n\r\n            # List to store paths of output video files\r\n            output_video_paths = []\r\n\r\n            # Process each chunk\r\n            for idx, chunk in enumerate(chunks, start=1):\r\n                segments = chunk.get('segments', [])\r\n\r\n                # Create .srt file for the chunk's segments\r\n                srt_content = \"\"\r\n                segment_number = 1\r\n                for segment in segments:\r\n                    start_time = segment['start']\r\n                    end_time = segment['end']\r\n                    text = segment['text']\r\n                    \r\n                    # Format the timestamps in HH:MM:SS,ms format (srt standard)\r\n                    start_timestamp = self.format_time(start_time)\r\n                    end_timestamp = self.format_time(end_time)\r\n                    \r\n                    # Add the subtitle segment to the .srt content\r\n                    srt_content += f\"{segment_number}\\n{start_timestamp} --> {end_timestamp}\\n{text}\\n\\n\"\r\n                    segment_number += 1\r\n\r\n                # Write .srt content to a file in 'srt' folder\r\n                srt_file_path = os.path.join(srt_folder, fr\"sliced_video_{idx}_subtitles.srt\")\r\n                with open(srt_file_path, 'w', encoding='utf-8') as srt_file:\r\n                    srt_file.write(srt_content)\r\n\r\n                # Input video file path\r\n                input_video_path = video_paths[idx - 1]\r\n\r\n                # Define output file path\r\n                output_video_path = os.path.splitext(input_video_path)[0] + '_subtitled.mp4'\r\n\r\n                # Overlay subtitles using ffmpeg-python\r\n                (\r\n                    ffmpeg\r\n                    .input(input_video_path)\r\n                    .filter('subtitles', srt_file_path)\r\n                    .output(output_video_path, codec='libx264', preset='medium', crf=23)\r\n                    .run(overwrite_output=True)\r\n                )\r\n                # Append output video file path to the list\r\n                output_video_paths.append(output_video_path)\r\n\r\n                # Clean up .srt file after use\r\n                os.remove(srt_file_path)\r\n\r\n            # Return as Data object containing array of output video file paths\r\n            return Data(data={\"output_video_paths\": output_video_paths})\r\n\r\n        except Exception as e:\r\n            # Handle any exceptions, log the error\r\n            print(f\"Error in build_output: {e}\")\r\n            # You may want to raise the exception or return an error Data object here\r\n            raise e\r\n\r\n    @staticmethod\r\n    def format_time(seconds):\r\n        \"\"\"Format seconds into HH:MM:SS,ms format (srt standard)\"\"\"\r\n        hours = int(seconds // 3600)\r\n        minutes = int((seconds % 3600) // 60)\r\n        seconds = seconds % 60\r\n        milliseconds = int((seconds - int(seconds)) * 1000)\r\n        return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Overlay transcription subtitles on videos based on provided chunks using ffmpeg-python","icon":"custom_components","base_classes":["Data"],"display_name":"Overlay Transcription","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["chunks","paths"],"beta":false,"edited":true},"id":"CustomComponent-mWoHe","description":"Overlay transcription subtitles on videos based on provided chunks using ffmpeg-python","display_name":"Overlay Transcription"},"selected":false,"width":384,"height":338,"dragging":false,"positionAbsolute":{"x":3689.9803712224893,"y":972.8060060727237}}],"edges":[{"source":"CustomComponent-4OU19","sourceHandle":"{œdataTypeœ:œAudioFile Loaderœ,œidœ:œCustomComponent-4OU19œ,œnameœ:œaudioFileœ,œoutput_typesœ:[œbytesœ]}","target":"CustomComponent-SlW53","targetHandle":"{œfieldNameœ:œaudioœ,œidœ:œCustomComponent-SlW53œ,œinputTypesœ:[œbytesœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"audio","id":"CustomComponent-SlW53","inputTypes":["bytes"],"type":"other"},"sourceHandle":{"dataType":"AudioFile Loader","id":"CustomComponent-4OU19","name":"audioFile","output_types":["bytes"]}},"id":"reactflow__edge-CustomComponent-4OU19{œdataTypeœ:œAudioFile Loaderœ,œidœ:œCustomComponent-4OU19œ,œnameœ:œaudioFileœ,œoutput_typesœ:[œbytesœ]}-CustomComponent-SlW53{œfieldNameœ:œaudioœ,œidœ:œCustomComponent-SlW53œ,œinputTypesœ:[œbytesœ],œtypeœ:œotherœ}"},{"source":"CustomComponent-SlW53","sourceHandle":"{œdataTypeœ:œOpenAIWhisperœ,œidœ:œCustomComponent-SlW53œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-aODsi","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-aODsiœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-aODsi","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"OpenAIWhisper","id":"CustomComponent-SlW53","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-SlW53{œdataTypeœ:œOpenAIWhisperœ,œidœ:œCustomComponent-SlW53œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-ParseData-aODsi{œfieldNameœ:œdataœ,œidœ:œParseData-aODsiœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"},{"source":"ParseData-aODsi","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-aODsiœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-DZ1VS","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DZ1VSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-DZ1VS","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-aODsi","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-aODsi{œdataTypeœ:œParseDataœ,œidœ:œParseData-aODsiœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-DZ1VS{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DZ1VSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"},{"source":"CustomComponent-SlW53","sourceHandle":"{œdataTypeœ:œOpenAIWhisperœ,œidœ:œCustomComponent-SlW53œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"CustomComponent-5TG3q","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œCustomComponent-5TG3qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"CustomComponent-5TG3q","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"OpenAIWhisper","id":"CustomComponent-SlW53","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-SlW53{œdataTypeœ:œOpenAIWhisperœ,œidœ:œCustomComponent-SlW53œ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-5TG3q{œfieldNameœ:œdataœ,œidœ:œCustomComponent-5TG3qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"},{"source":"CustomComponent-5TG3q","sourceHandle":"{œdataTypeœ:œTranscriptAudioœ,œidœ:œCustomComponent-5TG3qœ,œnameœ:œoutputœ,œoutput_typesœ:[œTextœ]}","target":"Prompt-4NImD","targetHandle":"{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-4NImDœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcript","id":"Prompt-4NImD","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TranscriptAudio","id":"CustomComponent-5TG3q","name":"output","output_types":["Text"]}},"id":"reactflow__edge-CustomComponent-5TG3q{œdataTypeœ:œTranscriptAudioœ,œidœ:œCustomComponent-5TG3qœ,œnameœ:œoutputœ,œoutput_typesœ:[œTextœ]}-Prompt-4NImD{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-4NImDœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"},{"source":"Prompt-4NImD","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-4NImDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"OpenAIModel-kxaTe","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-kxaTeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-kxaTe","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-4NImD","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-4NImD{œdataTypeœ:œPromptœ,œidœ:œPrompt-4NImDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-kxaTe{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-kxaTeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"},{"source":"OpenAIModel-kxaTe","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-kxaTeœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-wO22z","targetHandle":"{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-wO22zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"chunks","id":"CustomComponent-wO22z","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-kxaTe","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-OpenAIModel-kxaTe{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-kxaTeœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-wO22z{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-wO22zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"},{"source":"CustomComponent-wO22z","sourceHandle":"{œdataTypeœ:œTranscriptionChunkœ,œidœ:œCustomComponent-wO22zœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"CustomComponent-OLZ9A","targetHandle":"{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-OLZ9Aœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"chunks","id":"CustomComponent-OLZ9A","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"TranscriptionChunk","id":"CustomComponent-wO22z","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-wO22z{œdataTypeœ:œTranscriptionChunkœ,œidœ:œCustomComponent-wO22zœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-OLZ9A{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-OLZ9Aœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"},{"source":"CustomComponent-KuTs4","sourceHandle":"{œdataTypeœ:œVideoFile Loaderœ,œidœ:œCustomComponent-KuTs4œ,œnameœ:œvideoFileœ,œoutput_typesœ:[œbytesœ]}","target":"CustomComponent-OLZ9A","targetHandle":"{œfieldNameœ:œvideoœ,œidœ:œCustomComponent-OLZ9Aœ,œinputTypesœ:[œbytesœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"video","id":"CustomComponent-OLZ9A","inputTypes":["bytes"],"type":"other"},"sourceHandle":{"dataType":"VideoFile Loader","id":"CustomComponent-KuTs4","name":"videoFile","output_types":["bytes"]}},"id":"reactflow__edge-CustomComponent-KuTs4{œdataTypeœ:œVideoFile Loaderœ,œidœ:œCustomComponent-KuTs4œ,œnameœ:œvideoFileœ,œoutput_typesœ:[œbytesœ]}-CustomComponent-OLZ9A{œfieldNameœ:œvideoœ,œidœ:œCustomComponent-OLZ9Aœ,œinputTypesœ:[œbytesœ],œtypeœ:œotherœ}"},{"source":"CustomComponent-wO22z","sourceHandle":"{œdataTypeœ:œTranscriptionChunkœ,œidœ:œCustomComponent-wO22zœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"CustomComponent-mWoHe","targetHandle":"{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-mWoHeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"chunks","id":"CustomComponent-mWoHe","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"TranscriptionChunk","id":"CustomComponent-wO22z","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-wO22z{œdataTypeœ:œTranscriptionChunkœ,œidœ:œCustomComponent-wO22zœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-mWoHe{œfieldNameœ:œchunksœ,œidœ:œCustomComponent-mWoHeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"},{"source":"CustomComponent-OLZ9A","sourceHandle":"{œdataTypeœ:œSliceVideoœ,œidœ:œCustomComponent-OLZ9Aœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"CustomComponent-mWoHe","targetHandle":"{œfieldNameœ:œpathsœ,œidœ:œCustomComponent-mWoHeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"paths","id":"CustomComponent-mWoHe","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"SliceVideo","id":"CustomComponent-OLZ9A","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-OLZ9A{œdataTypeœ:œSliceVideoœ,œidœ:œCustomComponent-OLZ9Aœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-mWoHe{œfieldNameœ:œpathsœ,œidœ:œCustomComponent-mWoHeœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"}],"viewport":{"x":-1048.1303269394102,"y":-222.0372490792613,"zoom":0.4100864555983763}},"description":"Conversation Catalyst Engine.","name":"Viral Vid","last_tested_version":"1.0.9","endpoint_name":null,"is_component":false}